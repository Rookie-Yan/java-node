# 1. 线程

## 1. 分类、区别、优先级

* **线程的分类**
  
  * 用户线程：默认为用户线程 **虚拟机必须等待用户线程结束 **
  * 守护线程： *thread.setDeamon(true)* 设置为守护线程 **虚拟机不用等待守护线程结束**    GC线程
  
  
  
* **线程与进程的区别**
  
  * **线程是CPU调度和执行的基本单位。进程是系统资源分配的单位。**
  * **拥有资源：**进程是拥有资源的基本单位，而线程不拥有系统资源，但线程可以访问其隶属进程的系统资源。
  * **并发性：**不仅进程之间可以并发执行，而且多个线程之间也可以并发执行。
  * **系统开销：**创建或撤销进程时操作系统所付出的开销远大于创建或撤销线程时的开销。
  * **地址空间和其他资源 （如打开的文件）**：进程的地址空间之间互相独立，同一进程的各线程间共享进程的资源，某进程内的线程对于其他进程不可见。
  * **通信方面：**进程间通信需要进程同步和互斥手段的辅助，以保证数据的一致性， 而线程间可以直接读／写进程数据段（如全局变量）来进行通信。
  
  
  
* **线程的优先级**

  一共10个优先级，优先级大不一定先执行 只能是被调度的可能大，主线程的优先级为5，要设置（thread.setPriority()）时，先设置再start

  **如何解决优先级倒挂问题？**

  * **优先级天花板**：当任务使用资源时，就把任务的优先级提升到能访问资源的最高优先级，执行完成释放资源之后，把优先级再改回来
  * **优先级继承：**当任务1使用资源时，任务2抢占执行权，申请资源S，比较任务1和任务2的优先级，假如任务2优先级高，才提升任务1，提升到和任务2相同的优先级，当任务1释放资源后，将优先级再调整回来
  * **两者结合的方案：**当任务2使用资源S时，任务1抢占执行权，申请资源S，比较资源1和资源2的优先级，假如任务1优先级高，才提升任务2，提升到能访问资源S的最高优先级，当任务2释放资源后，将优先级再调整回来。



## 2. 线程的状态

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210307112056199.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NzgyMDM1NQ==,size_16,color_FFFFFF,t_70)

* **线程的五种状态： ** **创建、就绪、运行、阻塞、销毁**

* **线程什么时候会阻塞？**
  * sleep：线程休眠一段时间后转为**就绪状态**，在休眠期间处于**阻塞状态**，**占用资源**
  * wait：线程进入 **阻塞状态**，并 **释放资源**，使用notify或notifyAll后进入 **就绪状态**
  * join：使调用join的线程进入运行状态，而将当前正在运行的线程转为 **阻塞状态**，直到join的线程执行结束
  * IO阻塞：比如write和read





## 3. 线程的创建

### 1. **java中的四种创建方式**

* **继承Thread类创建线程**，重写run方法，之后在主线程中创建实体类，执行start方法 

```java
public class MyThread extends Thread{//继承Thread类
　　public void run(){//重写run方法}
}
public class Main {
　　public static void main(String[] args){
　　　　new MyThread().start();//创建并启动线程
　　}
}
```

*  **实现Runnable接口创建线程**，重写run方法，创建实体类，并将其作为Thread的参数，执行Thread.start()

```java
public class MyThread2 implements Runnable {//实现Runnable接口
　　public void run(){
      //重写run方法
　　}
}
public class Main {
　　public static void main(String[] args){
　　　　//创建并启动线程
　　　　MyThread2 myThread=new MyThread2();
　　　　Thread thread=new Thread(myThread);
　　　　thread().start();
　　　　//或者    new Thread(new MyThread2()).start();
　　}
}
```

* **使用Callable和Future创建线程**
  *  创建callable接口的实现类，并实现call方法，然后创建该实现类的实例
  *  使用FutureTask类来包装Callable对象，该FutureTask对象封装了Callable对象的call()方法的返回值
  *  使用FutureTask对象作为Thread对象的target创建并启动线程（因为FutureTask实现了Runnable接口）
  *  调用FutureTask对象的get()方法来获得子线程执行结束后的返回值

```java
public class Main {
　　public static void main(String[] args){
　　　MyThread3 th=new MyThread3();
　　　//使用Lambda表达式创建Callable对象
　　   //使用FutureTask类来包装Callable对象
　　　FutureTask<Integer> future=new FutureTask<Integer>(
　　　　(Callable<Integer>)()->{
　　　　　　return 5;
　　　　}
　　  );
　　　new Thread(future,"有返回值的线程").start();//实质上还是以Callable对象来创建并启动线程
　　  try{
　　　　System.out.println("子线程的返回值："+future.get());//get()方法会阻塞，直到子线程执行结束才返回
 　　 }catch(Exception e){
　　　　ex.printStackTrace();
　　　}
　　}
}
```

*  **使用线程池例如用Executor框架**,使用execute方法

```java
ExecutorService executorService = Executors.newFixedThreadPool(5); 
executorService.execute(new TestRunnable());  
```

* 使用callable和runable两种方式创建线程的区别
  * callable需要重写call，runable需要重写run
  * callable可以有返回值，runable没有返回值
  * callable可以抛出异常，runable不能抛出异常
  * callable使用ExecutorService的submit方法，runable使用execute方法。

### 2. **jvm中线程创建的流程？**

* main方法运行时进入栈中,创建新线程在栈中开辟新空间使用,栈空间相互隔离
* new的对象和对象中的成员变量进入堆,生成的地址值返回给栈去获取
* 每一个线程的栈中去执行自己的线程任务(run方法中的方法体)



## 4. 线程常用的方法

### 1. start与run

- run是在某个类中的普通方法，实际上没有开启新的线程；
- start是开启一条新的线程，然后调用其中的主方法。
- 即run没有开启新的线程，start开启了新的线程，所以一般使用start方法，重写run方法

### 2. sleep与wait

* sleep是**Thread**中的方法，表示的是线程休眠一段时间，之后进入就绪状态；wait是**Object**的方法，被final修饰，表示线程进入等待状态，直到被唤醒（notify或者notifyAll）
* sleep可以在任意地方使用，wait只能在同步方法或同步代码块中使用
* sleep不会释放锁，但也可以不要锁，wait是释放锁的，但是两者都会让出CPU
* sleep使用之后，阻塞一段时间（休眠）后会自动进入就绪状态，而wait使用之后是阻塞，直到被notify唤醒
* sleep和wait都需要捕获异常 InterruptedException ，并且都可以被打断 interrupted

### 3. yeild

线程的礼让，当前执行的线程让出cpu，进行上下文切换，并重新进入 **就绪状态**，交由CPU进行调度，所有有可能会礼让失败，继续执行原来的线程

### 4. join

线程的插入，如果在某个线程中调用t.join,那么会将当前线程转为 **阻塞状态**（其实调用的就是wait方法），直到t线程执行结束之后，才会重新执行原有线程。（不会调用notify方法，在t线程销毁时会自动调用notifyAll方法）

### 5. 线程的停止

可以使用stop或者interrupt方法进行停止，但过于粗暴，一般使用一个标志位进行线程的关闭。



## 5. 线程安全、同步、通信

### 1. 线程安全

当多个线程访问一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替执行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获得正确的结果，那这个对象就是线程安全的。

### 2. 线程同步

线程同步是指多线程通过特定的东西(如互斥量)来控制线程之间的执行顺序(同步)。主要通过锁机制实现，包括lock锁、synchronized、CAS等。

### 3. 线程通信

在一定条件下，A线程的操作能够被B线程感知。主要有 **共享内存** 和 **消息传递** 两种方式。包括volatile关键字，wait和notify，lock和signal，JUC的工具类等。



## 6. 池化技术

### 1. 池化技术的优点

- 降低资源的消耗—>线程复用，减少线程的创建和销毁
- 提高响应速度---->可以控制最大并发数，任务开始时不再需要创建线程
- 方便管理———>管理线程，限制了线程的无限制创建

### 2. 线程池的使用

* **四种创建方式**
  * **newCachedThreadPool：**创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。
  * **newFixedThreadPool：** 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。
  * **newScheduledThreadPool ：**创建一个定长线程池，支持定时及周期性任务执行。（其中可以设置延迟的时间和单位，使用的是schedule方法）
  * **newSingleThreadExecutor：** 创建一个单线程化的线程池，它只用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。

* **七个参数**（按参数设置顺序）
  * **corePollSize ：** 核心线程数，一开始就开启的
  * **maximumPoolSzie ：** 最大线程数 ，阻塞队列也满了时，才会开启的线程数量

  * **keepAliveTime** ： 线程池中非核心线程存好的时间，当开启了最大线程数之后，线程数少于核心线程数时，经过一段时间会进行销毁

  * **TimeUnit ：** 存活时间的单位 TimeUnit.SECONDS、 TimeUnit.Days等

  * **BlockingQueue：** 阻塞队列，当核心线程都使用时，后加入的线程会在阻塞队列进行等待

  * **ThreadFactory**：线程工厂，使用默认的就可以，一般不变

  * **RejectedExecutionHandler** **：**拒绝策略，当最大线程都开启，并且阻塞队列也满了的时候，对于再使用线程池时的策略 四种
* **四种拒绝策略**
  * **AbortPolicy()：** 不处理，直接抛出异常
  * **CallerRunsPolicy() ：**哪个线程向调用，就重新归还给他，让他去执行
  * **DiscardOldestPolicy() ：**尝试获取最早开启的、已使用完的线程，如果没有，就丢弃该线程任务
  * **DiscardPolicy()：**直接丢弃线程任务

### 3. 最大线程数的设置

* IO密集型
  * 适用场景：**任务中包含较多的IO读写任务，CPU执行效率不高，等待时间长**
  * 根据程序中十分消耗IO的线程数目设置，最少要多于这个数值，**一般设置成2倍**，因为消耗IO的线程会大量占用线程，可能造成阻塞，2倍时可以保证IO线程正常运行时，其他线程也可以进行
  
* CPU密集型
  * 适用场景：**任务多，但执行时间短，执行效率高的场景**
  * 最大线程数设置为电脑/服务器**CPU的个数**，可以保证CPU效率最高，Runtime.getRuntime().availableProcessors() 动态获取CPU个数
  
* 如果最优线程数设置过大（最大线程数超出了CPU所能处理的线程数）会有什么情况？

  ​		如果最大线程数设置的过大，会对CPU造成较大的负担。因为CPU处理线程使用的是时间片来进行管理的，给每个线程分配时间，时间片使用完后，会进行切换，转去执行其他线程。如果服务器本来可以处理20个线程，但线程池最大线程数设置为50，CPU就要额外的进行上下文的切换，存储线程执行的进程，保存和恢复线程的执行进度等，导致效率降低。

### 4. 阻塞队列工作机制如何实现的

​		使用类似于AQS的机制进行实现，使用一个state进行队列状态的标识。如果队列满，将其state置为1，后续进入的任务在尝试加入队列失败之后，会进行等待，直到队列被消费，state状态改为1，然后加入队列，等待消费。

​		在线程池中，如果核心线程数满，新加入的任务会尝试加入阻塞队列，如果此时队列满，就尝试使用非核心线程（创建），如果不满，就加入阻塞队列等待执行。

**常见的阻塞队列：**

- **ArrayBlockingQueue ：** 一个由数组结构组成的有界阻塞队列。
- **LinkedBlockingQueue ：** 一个由链表结构组成的有界阻塞队列。
- **PriorityBlockingQueue ：** 一个支持优先级排序的无界阻塞队列。
- **DelayQueue：** 一个使用优先级队列实现的无界阻塞队列。
- **SynchronousQueue：** 一个不存储元素的阻塞队列。
- **LinkedTransferQueue：** 一个由链表结构组成的无界阻塞队列。
- **LinkedBlockingDeque：** 一个由链表结构组成的双向阻塞队列。



### 5. 线程池的状态

![img](https://img-blog.csdn.net/20180514165513759?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoYWh1aHViYW8=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

线程池的5种状态：Running、ShutDown、Stop、Tidying、Terminated。



1、RUNNING

(1) 状态说明：线程池处在RUNNING状态时，能够接收新任务，以及对已添加的任务进行处理。 
(2) 状态切换：线程池的初始化状态是RUNNING。换句话说，线程池被一旦被创建，就处于RUNNING状态，并且线程池中的任务数为0！

```
private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));
```

2、 SHUTDOWN

(1) 状态说明：线程池处在SHUTDOWN状态时，不接收新任务，但能处理已添加的任务。 
(2) 状态切换：调用线程池的shutdown()接口时，线程池由RUNNING -> SHUTDOWN。

3、STOP

(1) 状态说明：线程池处在STOP状态时，不接收新任务，不处理已添加的任务，并且会中断正在处理的任务。 
(2) 状态切换：调用线程池的shutdownNow()接口时，线程池由(RUNNING or SHUTDOWN ) -> STOP。

4、TIDYING

(1) 状态说明：当所有的任务已终止，ctl记录的”任务数量”为0，线程池会变为TIDYING状态。当线程池变为TIDYING状态时，会执行钩子函数terminated()。terminated()在ThreadPoolExecutor类中是空的，若用户想在线程池变为TIDYING时，进行相应的处理；可以通过重载terminated()函数来实现。 
(2) 状态切换：当线程池在SHUTDOWN状态下，阻塞队列为空并且线程池中执行的任务也为空时，就会由 SHUTDOWN -> TIDYING。 
当线程池在STOP状态下，线程池中执行的任务为空时，就会由STOP -> TIDYING。

5、 TERMINATED

(1) 状态说明：线程池彻底终止，就变成TERMINATED状态。 
(2) 状态切换：线程池处在TIDYING状态时，执行完terminated()之后，就会由 TIDYING -> TERMINATED。



### 6. 核心线程与非核心线程

* 线程池的核心线程使用的是懒加载，任务开始提交时，会先判断线程数目是否小于核心线程数，小于的话就直接创建新的线程，作为核心线程重复使用；
* 如果此时大于核心线程数，会尝试放入阻塞队列中，如果阻塞队列没有满，就加入队列等待执行，如果满了，就尝试开启非核心线程，创建新的线程使用。
* 如果一段时间后阻塞队列不满了，但线程池拥有的线程数大于核心线程数，在保持keepAliveTime时间后，线程池会对非核心线程进行销毁，只保留核心线程数量的线程。



### 7. 项目中使用实例

​		对于一些需要但又不重要的操作创建一个单独的线程池负责操作。比如说登录信息的记录，日志信息的记录。在正常操作时，如果将日志记录交由主线程去做，尤其是并发较高的情况下，会使用户产生不好的体验。此时单独开辟一个线程池，在登录之后，或操作之后，记录相应的日志信息。参考Ruoyi项目中。

```java
	@Bean(name = "threadPoolTaskExecutor")
    public ThreadPoolTaskExecutor threadPoolTaskExecutor()
    {
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        executor.setMaxPoolSize(maxPoolSize);
        executor.setCorePoolSize(corePoolSize);
        executor.setQueueCapacity(queueCapacity);
        executor.setKeepAliveSeconds(keepAliveSeconds);
        // 线程池对拒绝任务(无线程可用)的处理策略
        executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());
        return executor;
    }
```



# 2. 锁

## 1. 锁的分类

### 1. **可重入锁**

1. 某个线程已经获得某个锁，可以再次获取锁而不会出现死锁。
2. **synchronized、ReentrantLock均为可重入锁**  ReentranLock手动释放锁次数一定要与重入次数一致，否则可能造成死锁
3. **原理**：每一个锁关联一个线程持有者和计数器，当计数器为 0 时表示该锁没有被任何线程持有，那么任何线程都可能获得该锁而调用相应的方法；当某一线程请求成功后，JVM会记下锁的持有线程，并且将计数器置为 1；此时其它线程请求该锁，则必须等待；而该持有锁的线程如果再次请求这个锁，就可以再次拿到这个锁，同时计数器会递增；当线程退出同步代码块时，计数器会递减，如果计数器为 0，则释放该锁。



### **2. 公平锁与非公平锁**

1. **公平锁：**锁按照资源请求的顺序进行分配，先来先获取锁，后到后获取锁

2. **非公平锁：**当线程需要使用资源的时候会先尝试获取锁，如果此时锁没有被占有（可能上一个线程使用完后释放了锁，并唤醒了队列中的线程，但此时唤醒的线程还没有被CPU调度），就会直接获取资源，不再进入队列，如果获取失败才会进入队列等待调度。

3. 使用：**synchronized为非公平锁、ReentrantLock默认为非公平锁。** 非公平锁可以减少CPU唤醒线程的开销，提高吞吐量。但是可能会导致线程饿死 

4. 实现原理：非公平锁和公平锁都维护了一个双向链表，每一个节点都存储一个线程。  

   **公平锁**  会判断当前队列中是否有线程，如果有就加入链表，进行等待，如果没有线程，就直接尝试获取锁；  

   **非公平锁**   在其基础上多加了一个标志位的判断，当资源被占用使，将state置为1，释放后置为0，在线程进行竞争使，首先获取state标志位，如果为0，说明此时资源未被占用，直接CAS尝试获取，否则加入队列，等待调度。



### **3. 共享锁和排他锁**

1. **共享锁：s锁，又称读锁。**允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。 允许别人读，但不能写    **select ... lock in share mode**

2. **排他锁：X锁，又称写锁。**允许获取排他锁的事务更新数据，阻止其他事务取得相同的数据集共享读锁和排他写锁。只能自己读写，不允许别人读写   **for update**

   

### **4. 乐观锁与悲观锁：**

1. 悲观锁：认为每次资源的使用都需要进行修改，所以对资源都进行加锁。**共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程 **   **synchronized、ReentrantLock 都为悲观锁。**  
2. 乐观锁：认为每次资源的使用都不需要进行修改，只对资源进行版本的记录。当版本号与预期不一致时，再进行回滚。 **CAS为乐观锁。**
3. 使用：乐观锁适用于读多写少的场景，悲观锁适用于写多读少的场景。**悲观锁阻塞事务，乐观锁回滚重试。**





## 2. AQS与CAS

### 1. CAS

* **介绍：**compare and swap 检查并更新 其中包含三个属性： **V：内存位置  A：预期原值 B：新值** 从某一内存上取值V，和预期值A进行比较，如果内存V上的值和预期值A的结果相等，那么我们就把新值B更新到内存，如果不相等，那么就重复上述操作直到成功为止。其操作具有**原子性**，与synchronized、lock相比，效率更高

* **实现：** 其方法底层都是调用的unsafe类里的方法，其操作都是**直接操作内存**的，使用的是c++中的方法，操作具有**原子性**

* **存在问题及解决：** 

  * ABA问题，即只关心是否为预期值，而不关心是否是一开始的预期值，可能其他线程已经对其进行操作，又重新设置为原来的值 ------ **通过AtomicStampedReference解决（原子引用）**，在原有的基础上携带一个时间戳（版本号）

  * 存在无限循环的问题，是通过自旋锁来实现的，所以会存在重复的空循环-----**通过LongAdder（原子累加器），分段CAS和自动分段迁移**

    * 首先由一个base值，当线程数没有达到阈值时，所有线程对于热点值的修改都是基于base的
    * 当并发的线程过多时，会将在内部创建cell数组，将并发线程分配到cell上进行处理
    * 如果某个线程对于cell的操作失败了，就会自动去找另外一个Cell分段内的value值进行CAS操作

  * 多变量原子问题 只能实现一个变量的原子操作-------**通过AtomicReference自定义封装对象解决**

    

### 2. AQS

* **AQS**：**AbstractQuenedSynchronizer**   **抽象的队列式同步器**  是阻塞式锁的抽象父类，如**ReentrantLock**等都是继承自AQS
* **实现原理：** 使用**state+CLH**队列实现
  * **state：** 使用**volatile** 关键字修饰，保证可见性，线程通过CAS去改变状态符，成功则获取锁成功，失败则进入等待队列，等待被唤醒。
  * **CLH队列：**（Craig，Landin，and Hagersten）队列是一个虚拟的双向队列，虚拟的双向队列即不存在队列实例，仅存在节点之间的关联关系。**AQS是将每一条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node），来实现锁的分配。**
* **工作流程：** 竞争线程在获取资源时，首先尝试获取state标志位的值，如果为1说明资源正在被占用，线程就会进入CLH阻塞队列进行自旋等待，一段时间后进行阻塞挂起。如果没有人占用，就会获取资源。



## 3. 锁升级和优化

### 1. 锁在对象头中的信息

![image-20210723162400106](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20210723162400106.png)

* **unused：**不使用

* **hashcode：**对象的哈希码  31bit

* **age：**分代年龄  4bit
* **epoch：** 其本质是一个时间戳 ， 代表了偏向锁的有效性

* **biased_lock：**偏向锁，0为无锁，1为偏向锁  1bit

* **最后锁标志位：**01 01 00 10 11 表示状态位  01为无所或偏向锁，00为轻量级锁，10为重量级锁，11为GC标记

* **ptr_to_lock_record：** 指向栈中锁记录的指针

* **ptr_to_heavyweight_monitor：**指向重量级锁的monitor的指针

  ​		创建一个对象之后，默认的就是**偏向锁**，但是会有延迟，可以设置延迟时间。也可以直接禁用掉偏向锁，就会直接使用轻量级锁。偏向锁的thread放的是当前偏向的线程id。因为一开始使用的是偏向锁，所以是没有hashcode的，当对象调用hashcode方法时，会从偏向锁转为无锁。轻量级锁使用的是栈帧中的锁记录，重量级锁使用的是monitor，来记录对象的hashcode。

### 2. 锁的升级

* **锁升级的整体流程：**

  * 如果仅有一条线程来竞争，锁就是偏向锁，线程ID会放入mark word的threadID中，当下次有线程来获取时，就会判断是否位记录的线程ID，如果是，就直接使用，如果不是，说明有多个线程在竞争，锁就会升级（膨胀）为轻量级锁
  * 轻量级锁主要解决的是竞争线程没有很多的时候的优化，会将mark word中线程ID那部分指向线程栈中的Lock Record，其中owner再指向mark word 实现绑定，获得锁的线程执行，其他线程自旋等待，当自旋个数超过CPU核数的一半 或者自旋次数超过10次才会升级成重量级锁
  * 重量级锁，使用monitor监视器来实现，依赖于操作系统mutex中的lock，需要系统调用引起的内核态与用户态切换、线程阻塞造成的线程切换等，操作最严格，CPU消耗最大

* **偏向锁**

  * 偏向锁**不存在解锁操作**，在使用结束后，线程ID依旧会保存在对象头中。
  * 当非偏向线程进行锁获取时，偏向锁会进行撤销。首先判断偏向线程是否执行结束，如果结束，就会撤销偏向锁，改为无锁，之后再次设置偏向线程的ID，升级为偏向锁。（本质还是从一个偏向到另一个偏向，只是中间经历了无锁状态，不算锁降级）
  * 如果偏向线程没有执行结束，就会升级为轻量级锁
  * 如果多个资源都被一个线程使用，并且在一段时间内，都进行了重偏向（默认20个资源），那么认为该线程已经执行结束，会进行整体的锁偏向，偏向之前频繁请求资源的新的线程。

* **轻量级锁是如何实现的？**

  * 通过AQS原理尝试获取对象锁，获取标志位（这里使用的是对象头锁状态，如果是00说明为轻量级锁，即有线程占用，否则为01说明为偏向锁，没有占用）
  * 在获取成功后，在线程的栈帧中创建Lock Record，记录锁状态，其中包括对象的引用地址，还有owner，其中owner记录了使用对象的对象头信息，包括hashcode，分代年龄等。之后，再将对象的对象头指向lock record，并将锁状态改为00，表示轻量级锁，被占有。（也可以理解为Lock Record中的头信息与Object中的头信息进行了互换，进行绑定）
  * 如果获取失败，则会加入队列中进行自旋，直到获取到锁，或者升级为重量级锁。

  

### 3. 锁的优化

* 锁粗化：锁粗化指的是有很多操作都是对同一个对象进行加锁，就会把锁的同步范围扩展到整个操作序列之外。
* 锁消除：锁消除指的是JVM检测到一些同步的代码块，完全不存在数据竞争的场景，也就是不需要加锁，就会进行锁消除。
* 自适应锁：自旋锁会导致CPU空转，自适应锁可以根据前一次在同一个锁上的自旋时间和锁的持有者状态来决定自旋的次数。



## 4. Synchronized

### 1. 底层实现原理

* JVM层面

  ​		synchronized指令编译之后使用**mointorenter**和**mointorexit**两个字节码指令来使线程同步。它们分别位于同步代码块的开始和结束位置。当jvm执行到monitorenter指令时，当前线程试图获取monitor对象的所有权，如果未加锁或者已经被当前线程所持有，就把锁的计数器+1；当执行monitorexit指令时，锁计数器-1；当锁计数器为0时，该锁就被释放了。如果获取monitor对象失败，该线程则会进入阻塞状态，直到其他线程释放锁。mointor 管程/监视器 相当于一个同步队列，只有一个线程可以使用。

  ​		其中monitor对象又具体包括**owner、WaitSet、EntryList、recursions、count**。

  * owner存储的是当前使用锁的线程ID
  * WaitSet存放处于wait状态的线程，之前获取过锁，但现在处于wait状态，可以被唤醒的。唤醒后重新进入EntryList竞争
  * EntryList存放处于block状态的线程，等待获取锁但从未获得锁。在线程需要竞争时，先通过CAS进行短暂的自旋，如果锁很快释放，就直接获取，不需要进入阻塞队列
  * recursions记录重入次数
  * count 约为_WaitSet 和 _EntryList 的节点数之和
  * cxq: 多个线程争抢锁，会先存入这个单向链表 _cxq 和 _EntryList共同管理多线程竞争锁的过程

  <img src="https://img-blog.csdnimg.cn/20210310134906684.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x1Y2t5X2xvdmU4MTY=,size_16,color_FFFFFF,t_70" alt="img"  />

  ​		使用synchronized需要频繁地切换操作系统从**用户态切换到内核态**，消耗性能。从内存的角度来说，加锁会清除工作内存中的共享变量，然后从主内存中读取，释放锁是把工作内存中的共享变量写回主内存。

  * 用户态：只能访问受限的内存，且不允许访问外部设备，包括磁盘的读写等。
  * 内核态：可以通过CPU访问所有的数据，所有的外部设备。
  * 切换：**系统调用、异常、外围设备的中断**

* 操作系统层面

  ​	底层使用的是操作系统的Mutex Lock（互斥锁）。操作系统底层的锁主要分为两类，**互斥锁和自旋锁。** 

  * 互斥锁在加锁失败后，请求线程会**释放** **CPU** ，给其他线程；**对于互斥锁加锁失败⽽阻塞的现象，是由操作系统内核实现的**，加锁失败，内核将线程置为睡眠，直到资源释放再在合适的实际进行唤醒。互斥锁将唤醒交给内核，但是增加了上下文切换的开销。运行--睡眠--就绪。Mutex变量的值为1表示互斥锁空闲，这时某个进程调用lock可以获得锁。上锁后进入临界区，只能有一个线程对临界区数据进行操作。
  * 自旋锁：加锁失败后，线程会**忙等待**，直到它拿到锁；通过 CPU 提供的 CAS 函数（*Compare And Swap*），在⽤户态完成加锁和解锁操作，不会主动产生线程上下⽂切换。



### 2. 使用的场景和区别

* **修饰变量和方法**：被修饰变量和方法的对象实例只能一个线程使用
* **修饰class类：**被修饰的class只能被一个线程使用（带static的方法或变量被锁，其class也会被上锁）
* **修饰同步代码块：**对代码块内的对象加锁
* **修饰常量：** 因为常量不会被修改，所以是线程安全的，可能会锁消除。如果锁String或者Integer等，如果对其操作，可能会生成新对象，地址发生改变，所以锁失效。
* 八锁问题：使用同一把锁的线程执行先后顺序一定是按照拿到锁的顺序执行，不使用同一把锁的线程执行先后顺序是按照CPU的调度（需要考虑人为延迟）。（八锁问题常借助延时函数，只是为了让效果更加清晰）。



### 3. 加锁机制

* 使用wait和notify进行线程同步和线程通信。
  * **wait** 使当前线程进入阻塞状态，并释放当前线程占有的资源。 **wait释放资源**
  * **notify** 由CPU随机唤醒阻塞队列中的一个线程，准备获取资源。  **notify不释放资源，仅唤醒线程，notify后当前线程继续工作**
  * wait和notify必须在synchronized代码块中使用。因为两者使用的前提是线程拥有锁。
* synchronized为**非公平锁**，允许资源的抢占。
* synchronized**不可打断**，在进入同步代码块之后必须执行结束。



## 5. Lock

### 1. 分类

* ReentrantLock 可重入锁 **默认无参构造是非公平锁**，加入参数true是公平锁
* ReentrantReadWriteLock.ReadLock 读锁 **可以由多个线程进行获取，并且多个线程可重入**。在读多写少的情况下可以提高并发量，提高效率
* ReentrantReadWriteLock.WriteLock 写锁 。读锁和写锁的切换在于一个32位标志位的高16位于低16位的转换。**不支持写锁的升级**，必须读锁全部释放才能获取写锁。但是**必须执行锁的降级**，当前线程拥有写锁，先变为读锁，之后再释放锁，由其他线程进行竞争。

### 2. 底层原理

​		**AQS和CAS，通过CAS尝试获取锁，获取失败就通过自旋，加入阻塞队列等待调度。**

### 3. 加锁机制

* **lock与unlock：**加锁与解锁，需要手动释放锁，并且解锁次数要与重入次数想匹配
* **trykock：** 尝试获取锁，可以设置等待时间，如果超出等待时间，线程就会放弃对资源的请求，转去执行else逻辑
* **interrupt：** 使用lock.lockInterruptibly()对资源进行加锁时，此锁是可以被其他线程使用interrupt方法进行打断，之后原线程进行catch逻辑处理
* 非公平锁：默认非公平锁，可以将构造函数赋值true，构造公平锁



## 6. volatile

* 可见性：volatile修饰的变量被标记为**共享变量**，**强制从主存中读取，修改后强制写回主存**，保证**变量的修改对所有线程是可见**的
* 禁止指令重排（内存屏障）：编译器在生成字节码时，会在指令序列中插入内存屏障来**禁止特定类型的处理器重排序** 计算机在编译时会对代码进行重新排序，进行优化，但也可能因此产生错误
* 原子性：**不保证原子性**，无法保证并发情况下执行结果与预期的一致，中途如果被打断，更新值有可能失效（i++）
* 单例模式的使用：**DCL双重检测锁+volatile关键字修饰对象**（主要为了避免指令重排引发的错误）



## 7. 对比

### 1. synchronized与lock

* synchronized是**关键字**，属于**JVM层面**，Lock是一个**接口**，属于JDK层面封装的**API**。
* synchronized会**自动释放**锁，而Lock必须**手动释放**锁。
* synchronized是**不可中断**的，Lock**可以中断**也可以不中断。
* Lock**可以知道线程有没有拿到锁** （Thread.hold（资源）），而synchronized不能。
* synchronized能锁住**方法、代码块和class类**，而Lock只能锁住**代码块**。
* synchronized是**非公平锁**，ReentrantLock可以控制是否是公平锁，**默认为非公平锁**。
* synchronized在**获取锁失败之后只能继续等待**，Lock可以使用**设置等待时间**。
* synchronized存在升级机制，且不可逆，一旦升级为重量级，对于CPU资源的耗费较大。

### 2. synchronized与volatile

* volatile 仅能使用在**变量级别，**synchronized 则可以使用在**变量、方法、类级别、代码块**上。
* volatile 仅仅能实现变量修改可见性，并**不能保证原子性**，synchronized 可以实现变量的修改可见性和**保证原子性**。
* volatile **不会造成线程阻塞**，synchronized 可能会**造成线程阻塞**。
* volatile 标记的变量不会被编译器优化（**禁止指令重排**），synchronized 标记的变量**可以被编译器优化**。
* volatile 修饰的变量，jvm 每次都从主内存中读取，而不会从寄存器（工作内存）中读取。synchronized 表示只有一个线程可以获取作用 对象 的锁，执行代码，阻塞其他线程。



## 8. 死锁

### 1. 产生条件

* 互斥条件：**多个线程不能同时使用同⼀个资源**
* 持有并等待条件：**线程** **A** **在等待资源** **2** **的同时并不会释放自己已经持有的资源** 
* 不可剥夺条件：当线程已经持有了资源 ，**在自己使用完之前不能被其他线程获取**
* 环路等待条件；**两个线程获取资源的顺序构成了环形链**

### 2. 死锁的排查

1. 使用jps获取线程及端口号（pid）
2. 使用jstack+pid 查看线程信息，对比锁的持有信息



# 3. 线程安全类

## 1. JUC包

<img src="D:\Typora\image\image-20210724150715015.png" alt="image-20210724150715015" style="zoom:80%;" />

## 2. ConcurrentHashMap

* 如何保证线程安全？
  * 在java1.7中，使用的是Sagment+HashEntry，分段锁机制，在使用时设置并发量（即Sagment段数），然后在使用时对需要使用的HashEntry所对应的Sagment进行加Synchronized锁
  * 在java1.8中，使用的Node+CAS进行加锁，因为1.8使用头插法，所以在对资源修改时，使用CAS尝试获取请求头，如果成功，就使用Synchronized对头节点进行加锁。而在get节点时，node节点的value和next都使用volatile进行修饰，保证修改可见，并且使用copy on write，即使map进行扩容，也不影响读数据
* 如何使用锁机制的
  * java1.7中使用分段锁+Synchronized
  * java1.8中使用分段锁+CAS+volatile+Synchronized



## 3. CopyOnWrite

### 1. fast-fail机制

​		fail-fast 机制，即**快速失败机制**，是java集合(Collection)中的一种错误检测机制，在ArrayList和HashMap中都有体现。

​		fail-fast机制并不保证在不同步的修改下一定会抛出异常，它只是尽最大努力去抛出，所以这种机制一般仅用于检测bug。

​		其底层是依靠modcount变量，该变量在每次add、remove、clear等操作时就会进行自增。在集合的forEach、hasNext等方法中，会先存储一个modcount的原值，在方法中或执行方法后会比较当前值和原值，如果不一致，则抛出ConcurrentModificationException异常。

**避免fail-fast**

* 在单线程条件下，如果需要在Iterator遍历过程中操作，要使用Iterator中的方法，其不会修改modcount
* 在多线程条件下，使用线程安全的集合，如CopyOnWriteArrayList、ConcurrentHashMap



### 2. CopyOnWriteArrayList

* 使用的读写分离的思想，其底层依靠数组实现，并且数组使用volatile进行修饰（修饰的是数组引用），保证其可见性。

* 允许多线程对其进行不加锁的读操作（get）

* 对于写操作（remove、add），会在其方法上加synchronized（final修饰，只有一把），保证只有一个线程会对其进行写操作。并且在写操作时，会先将数组复制一份，然后在其备份上进行修改。之后再将原数组的指针指向新数组，并且因为volatile，其修改会对读操作可见（具有时延，如果读的同时发生写操作，可能会无法获取新元素）

  ```java
  private transient volatile Object[] array;//volatile修饰的对象数组，保证可见，不被序列化
  final transient Object lock = new Object();//只是用来线程同步的一个对象
  public boolean add(E e) {
          synchronized (lock) {
              Object[] elements = getArray();
              int len = elements.length;
              Object[] newElements = Arrays.copyOf(elements, len + 1);
              newElements[len] = e;
              setArray(newElements);
              return true;
          }
      }
  ```

### 3. CopyOnWriteArraySet

​		其内部其实是维护了一个CopyOnWriteArrayList，其主要的方法即通过CopyOnWriteArrayList中的方法实现

### 4. COW的缺点

* **内存占用问题：** 在进行写操作时需要将原有数组复制然后进行写操作，但当原数组对象较大时，消耗内存较大，可能频繁引发GC
* **数据一致性问题：**CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。

### 5. 对比ReentrantReadWriteLock

* 相同点：
  * **都使用读写分离的思想**
  * **读线程互相不堵塞**
* 不同点：
  * CopyOnWrite通过牺牲数据的实时性来保证数据的最终一致性，因此**不会存在等待的情况**，即读的同时也可以写，写的同时也可以读，但**读线程对数据的更新是延时感知**的，**可能会造成脏读**。
  * ReentrantReadWriteLock在读锁获取后写线程需要等待，写锁获取后读线程就需要等待。即**依旧存在线程阻塞等待的问题**。但也因此**解决了COW脏读的问题**。



## 4. HashTable和Vector

### 1. HashTable

​		Hashtable是线程安全的双列集合，同HashMap一样，采用**数组加链表**的形式进行存储，而且采用的是**头插法**。在解决线程安全问题上，在**方法层面**全部使用Synchronized关键字进行修饰。对比HashMap，有以下不同：

* HashMap的key、value均可以为null，HashTable不允许。
* HashMap的默认初始容量为16，HashTable为11。
* HashMap的扩容为原来的 2 倍，HashTable 的扩容为原来的 2 倍加 1。
* HashMap是非线程安全的，HashTable是线程安全的。
* HashMap的 hash 值重新计算过，HashTable 直接使用对象的HashCode。
* HashMap去掉了 HashTable 中的 contains 方法。
* HashMap继承自 AbstractMap类，HashTable 继承自Dictionary 类。

### 2. Vector

​		Vector是**线程安全的单列集合**，同ArrayList一样，继承AbstractList类，采用的是**数组**的形式进行存储。具有Arraylist的特点（查找快，插入慢），但扩容与其不同，采用100%增量或自定义增量扩容。

![image-20210724203601678](D:\Typora\image\image-20210724203601678.png)



## 5. ThreadLocal

### 1. 使用场景

* **线程隔离：** 每个线程单独复制一份变量存储在自身线程中，防止多线程操作互相影响
* **上下文通信：** 将整个request都需要用到的参数、变量存放，可以减少参数的传递 

### 2. 底层原理

​		ThreadLocal中有一个**静态内部类ThreadLocalMap**，在Thread中有一个**实例化**的ThreadLocalMap，**ThreadLocals**，ThreadLocals中以Entry（key-value）的形式存储了多个ThreadLocal及该线程所对应的值。对ThreadLocal的操作其实操作的就是每个线程中的ThreadLocals，其中**key是ThreadLocal对象**（具体是通过hashcode进行标识的），**value是存储的对象**。在操作时先通过当前线程获取ThreadLocals，再通过查找ThreadLocal获取需要操作的值。

```java
//静态内部类 
static class ThreadLocalMap {
        /**
         * The entries in this hash map extend WeakReference, using
         * its main ref field as the key (which is always a
         * ThreadLocal object).  Note that null keys (i.e. entry.get()
         * == null) mean that the key is no longer referenced, so the
         * entry can be expunged from table.  Such entries are referred to
         * as "stale entries" in the code that follows.
         */
        static class Entry extends WeakReference<ThreadLocal<?>> {//key为弱引用
            /** The value associated with this ThreadLocal. */
            Object value;

            Entry(ThreadLocal<?> k, Object v) {//这是一个构造方法
                super(k);
                value = v;
            }
        }
//get 方法
public T get() {
        Thread t = Thread.currentThread();//获取当前线程
        ThreadLocalMap map = getMap(t);//获取当前线程的map
        if (map != null) {//如果当前线程不为null
            ThreadLocalMap.Entry e = map.getEntry(this);//获取当前ThreadLocal的Entry
            if (e != null) {//如果不为空
                @SuppressWarnings("unchecked")
                T result = (T)e.value;//返回Entry的value
                return result;
            }
        }
        return setInitialValue();
    }
//getEntry方法  
private Entry getEntry(ThreadLocal<?> key) {
        int i = key.threadLocalHashCode & (table.length - 1);
        Entry e = table[i];//获取一个与ThreadLocal相关的Entry
        if (e != null && e.get() == key)
            return e;
        else
            return getEntryAfterMiss(key, i, e);
    }
```

### 3. 结构设计

* **关于内存泄漏：**在ThreadLocals中的key是使用的ThreadLocal的弱引用，而value使用的是value的强引用。
  * 如果key使用强引用，当ThreadLocal使用结束后，它仍然被ThreadLocals所引用，所以无法进行GC，就会造成内存泄漏
  * 如果使用的是弱引用，当ThreadLocal使用完之后，会因为弱引用被GC回收，从而导致key为null，但是此时value还被实际数据强引用，所以此时如果不进行remove，就会造成内存泄漏。
  * 虽然ThreadLocals交由Thread管理，Thread销毁后也会随之销毁，但在多线程环境下，一般使用线程池，线程重复使用，不会销毁，所以ThreadLocals也不会轻易销毁。
  * 所以**无论强引用还是弱引用，都有可能会造成内存泄漏**，所以手动remove是非常有必要的。

<img src="D:\Typora\image\image-20210724184918812.png" alt="image-20210724184918812" style="zoom:50%;" />

* **关于弱引用：** 虽然弱引用依旧可能会造成内存泄漏，但是**可以一定程度上减少内存泄漏**的出现。在ThreadLocalMap的方法中，set和getEntry方法会在尝试获取key时判断是否key==null，如果为null，说明此key已经被GC回收，可以直接使用该位置进行存储。所以**当使用get、set、remove时，ThreadLocal会自动对key==null的Entry进行回收**，将key已经失效的Entry进行清除。但如果没有频繁的使用ThreadLocals，依然会造成内存泄漏，所以最好的方法仍然时手动remove。

* **关于哈希冲突：** ThreadLocalMap的实现其实是基于Entry数组实现的，并没有继承map，所以其中的哈希冲突和hashmap也不太一致。它使用 **线性探测法** 避免哈希冲突。

  ```java
  //初始化数组长度为16，以后扩容必须是2的次幂
  private static final int INITIAL_CAPACITY = 16;
  //初始化一个Entry数组
  private Entry[] table;
  //记录Entry中Entry的个数
  private int size = 0;
  //数组进行扩容的阈值
  private int threshold; // Default to 0
  //设置默认阈值为长的的2/3
  private void setThreshold(int len) {
      threshold = len * 2 / 3;
  }
  ```

  * 当插入一个元素的时候，会先通过hashcode进行遍历查找（此处的hashcode使用的是一个AtomicInteger，每当创建一个ThreadLocal就在原基础上加HASH_INCREMENT = 0x61c88647，这样可以使对象在2的次幂的长度上进行更加均匀的分布），查看已有的key值，是否为null（如果为null说明已经被回收，可以直接在其基础上进行设置），是否为需要的key（说明ThreadLocal的key-value键值对已经存在，直接覆盖）
  * 遍历查找就是根据数组下标依次查看，其起始位置与hashcode有关的，所以遍历其实是一个环形遍历（5-16-1-4）
  * 如果遍历结束之后没有找到key==null或者key==目标ThreadLocal，说明Entry不存在，需要创建新的Entry，加入数组之后再判断数组是否需要进行扩容。

* **关于map的位置：** 在ThreadLocal中，map是交由每一个Thread进行维护的，其Entry为ThreadLocal+value，而不是由ThreadLocal维护，其Entry为Thread+value。

  * 交由Thread维护可以减少map中Entry的数量，可以减少扩容操作。（实际生产中线程数要大于ThreadLocal实例个数）
  * 交由Thread维护，当线程使用结束销毁后，ThreadLocalMap也会随之销毁，可以减少内存的使用。



## 6. JUC工具类

* **ConutDownLatch 减法计数器**：当计数器为0时，执行await方法

  ```java
  CountDownLatch countDownLatch=new CountDownLatch(10);//创建一个倒计时的计数器
  countDownLatch.countDown();//使计数器减一，放在线程里面执行
  countDownLatch.await();//等待计数器归零之后再执行后续，确保线程执行完毕
  ```

* **CyclicBarrier加法计数器**

  ​		CyclicBarrier有两种构造方法，一种是只有一个数字，表示到什么时候，一种是数字加runnable类，到什么时候走什么方法
  c.await();表示计数器加一，当计数器的值为预设值时，就会执行后续的方法.

  ```java
  CyclicBarrier c=new CyclicBarrier(7,()->{
              System.out.println("我真的没有开挂");
          });
          for (int i = 0; i < 21; i++) {
              final int number=i;
              new Thread(()->{
                  try {
                      Thread.sleep(100*number);
                      //i是无法直接在线程中用的，需要使用final关键字修饰才能够拿到
                      System.out.println("上了一波分"+number);
  
                      c.await();
                  } catch (InterruptedException e) {
                      e.printStackTrace();
                  } catch (BrokenBarrierException e) {
                      e.printStackTrace();
                  }
              }).start();
          }
  ```

* **Semaphore 信号量**

  ​		预定一个信号量数值，当信号量没有的时候，其他线程就会等待，如果有就可以获得。**并发限流，限制最大线程数**

  ```java
  Semaphore s=new Semaphore(7);
  for (int i = 0; i < 21; i++) {
      final int number=i;
      new Thread(()->{
          try {
              s.acquire();//获得信号量
              Thread.sleep(100*number);
              System.out.println("上了一波分"+number);
          } catch (Exception e) {
              e.printStackTrace();
          } finally {
              s.release();//释放信号量
          }
      }).start();
  ```

  

## 7. Collections.synchronized

​		可以使用collections类中的synchronized集合包装类来保证线程安全，其底层也是使用的synchronized进行加锁实现线程同步。

![image-20210724215414865](D:\Typora\image\image-20210724215414865.png)
