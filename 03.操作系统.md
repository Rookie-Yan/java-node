# 处理器的管理功能

（1）**处理机管理：**对处理机的管理可归结为对进程的管理。**进程管理的主要功能包括进程控制、进程同步、进程通信、死锁处理、处理机调度等。**

**（2）存储器管理：**主要包括内存分配与回收、地址映射、内存保护与共享和内存扩充等功能。

**（3）文件管理：**文件管理包括文件存储空间的管理、目录管理及文件读写管理和保护等

**（4）设备管理：**设备管理的主要任务是完成用户的I/O请求，方便用户使用各种设备，并提高设备的利用率，主要包括缓冲管理、设备分配、设备处理和虚拟设备等功能。



内核：微内核（提供最基本的功能）、宏内核（带上一些扩展功能）、混合内核



# 1. 进程管理

## 1. 进程

### 进程的状态

![image-20210520154328486](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20210520154328486.png)

### 进程的上下文切换

**⼀个进程切换到另⼀个进程运⾏，称为进程的上下⽂切换**。

上下文切换场景：

* 为了保证所有进程可以得到公平调度，CPU 时间被划分为⼀段段的时间⽚，这些时间⽚再被轮流分配给各个进程。这样，当某个进程的时间⽚耗尽了，进程就从运⾏状态变为就绪状态，系统从就绪队列选择另外⼀个进程运⾏；

* 进程在系统资源不⾜（⽐如内存不⾜）时，要等到资源满⾜后才可以运⾏，这个时候进程也会被挂起，并由系统调度其他进程运⾏；

* 当进程通过睡眠函数 sleep 这样的⽅法将⾃⼰主动挂起时，⾃然也会重新调度；

* 当有优先级更⾼的进程运⾏时，为了保证⾼优先级进程的运⾏，当前进程会被挂起，由⾼优先级进程来运⾏；

* 发⽣硬件中断时，CPU 上的进程会被中断挂起，转⽽执⾏内核中的中断服务程序





### 💾进程间的通信

* 管道：单向传输，放入管道后必须拿出，才能继续使用，效率低    匿名管道（父子关系进程间进行）不匿名管道 不同进程
* 消息队列：**是保存在内核中的消息链表**
* 共享内存：**共享内存的机制，就是拿出⼀块虚拟地址空间来，映射到相同的物理内存中**。
* 信号量：**信号量其实是⼀个整型的计数器，主要⽤于实现进程间的互斥与同步，⽽不是⽤于缓存进程间通信的数据**。 PV操作
* 信号：**对于异常情况下的⼯作模式，就需要⽤「信号」的⽅式来通知进程。**是进程间通信机制中**唯⼀的异步通信机制**
* Socket：**跨⽹络与不同主机上的进程之间通信**





### 调度方式

**（1）非剥夺调度方式， 又称非抢占方式。** 非剥夺调度方式是指当一个进程正在处理机上执行时，即使有某个更为重要或紧迫的进程进入就绪队列，仍然让正在执行的进程继续执行，直到该进程完成或发生某种事件而进入阻塞态时，才把处理机分配给更为重要或紧迫的进程。

**（2）剥夺调度方式，又称抢占方式。**剥夺调度方式是指当一个进程正在处理机上执行时， 若有某个更为重要或紧迫的进程需要使用处理机，则立即暂停正在执行的进程，将处理机分配给这个更为重要或紧迫的进程。



### 💾调度算法

**（1）先来先服务（FCFS）调度算法**：每次从就绪队列中选择最先进入该队列的进程，将处理机分配给它，使之投入运行，直到完成或因某种原因而阻塞时才释放处理机。

**（2）短作业优先（SJF）调度算法：**从后备队列中选择一个或若干估计运行时间最短的作业，将它们调入内存运行。

**（3）优先级调度算法**：在作业调度中，优先级调度算法每次从后备作业队列中选择优先级最高的一个或几个作业，将它们调入内存，分配必要的资源，创建进程并放入就绪队列。在进程调度中，优先级调度算法 每次从就绪队列中选择优先级最高的进程，将处理机分配给它，使之投入运行。

（3.1）非剥夺式优先级调度算法。当一个进程正在处理机上运行时，即使有某个更为重要或紧 迫的进程进入就绪队列，仍然让正在运行的进程继续运行，直到由于其自身的原因而主动让出处理机时（任务完成或等待事件），才把处理机分配给更为重要或紧急的进程。

（3.2）剥夺式优先级调度算法。当一个进程正在处理机上运行时，若有某个更为重要或紧迫的进程进入就绪队列，则立即暂停正在运行的进程，将处理机分配给更重要或紧迫的进程。

**（4）高响应比优先调度算法**：在每次进行作业调度时，先计算后备作业队列中每个作业的响应比，从中选出响应比最高的作业投入运行。响应比计算公式：响应比=（等待时间+要求服务时间）/要求服务时间

**（5）时间片轮转调度算法**：时间片轮转调度算法主要适用于分时系统。在这种算法中，系统将所有就绪进程按到达时间的先后次序排成一个队列，进程调度程序总是选择就绪队列中的第一个进程执行，即先来先服务的原则，但仅能运行一个时间片，如 lOOms。在使用完一个时间片后，即使进程并未完成其运行，它也必须释放出（被剥夺）处理机给下一个就绪的进程，而被剥夺的进程退回到就绪队列的末尾重新排队，等候再次运行。

**（6）多级反馈队列调度算法：**①）设置多个就绪队列，并为各个队列赋予不同的优先级；②赋予各个队列中进程执行时间片的大小各不相同，在优先级越高的队列中，每个进程的运行时间片越小；③一个新进程进入内存后，首先将它放入第 l 级队列的末尾，按 FCFS 原则排队等待调度。当轮到该进程执行时，如l它能在该时间片内完成， 便可准备撤离系统；若它在一个时间 片结束时尚未完成，调度程序便将该进程转入第2级队列的末尾，再同样按 FCFS 原则等 待调度执行；若它在第2级队列中运行一个时间片后仍未完成，再以同样的方法放入第 3 级队列……如此下去，当一个长进程从第1级队列依次降到第 n 级队列后，在第 n 级队 列中便采用时间片轮转的方式运行。④仅当第 l 级队列为空时，调度程序才调度第 2 级队列中的进程运行；仅当第 l～(i-1）级队列均为空时才会调度第i级队列中的进程运行。





## 2. 线程

### 线程和进程的区别

线程最直接的理解就是“轻量级进程”，它是一个基本的CPU执行单元，也是程序执行流的最小单元，由线程ID、程序计数器、寄存器集合和堆栈组成。

* **调度：**线程是独立调度的基本单位，进程是拥有资源的基本单位。
* **拥有资源：**进程是拥有资源的基本单位，而线程不拥有系统资源，但线程可以访问其隶属进程的系统资源。
* **并发性：**不仅进程之间可以并发执行，而且多个线程之间也可以并发执行。
* **系统开销：**创建或撤销进程时操作系统所付出的开销远大于创建或撤销线程时的开销。
* **地址空间和其他资源 （如打开的文件）**：进程的地址空间之间互相独立，同一进程的各线程间共享进程的资源，某进程内的线程对于其他进程不可见。
* **通信方面：**进程间通信需要进程同步和互斥手段的辅助，以保证数据的一致性， 而线程间可以直接读／写进程数据段（如全局变量）来进行通信。



### 💾死锁的形成

* 互斥条件：**多个线程不能同时使⽤同⼀个资源**

* 持有并等待条件：**线程** **A** **在等待资源** **2** **的同时并不会释放⾃⼰已经持有的资源** 

* 不可剥夺条件：当线程已经持有了资源 ，**在⾃⼰使⽤完之前不能被其他线程获取**

* 环路等待条件；**两个线程获取资源的顺序构成了环形链**



## 3. 互斥与同步

互斥：一个线程在临界区执行的时候，其他线程被组织进入临界区

同步：并发进程/线程在⼀些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通信息称为进程/线程同步。

实现：锁、信号量（PV操作）

**信号量semaphore：**信号量是操作系统提供的⼀种协调共享资源访问的⽅法。

通常**信号量表示资源的数量**，对应的变量是⼀个整型（ sem ）变量。

另外，还有**两个原⼦操作的系统调⽤函数来控制信号量的**，分别是：

*P* 操作：将 sem 减 1 ，相减后，如果 sem < 0 ，则进程/线程进⼊阻塞等待，否则继续，表明 P操作可能会阻塞；

*V* 操作：将 sem 加 1 ，相加后，如果 sem <= 0 ，唤醒⼀个等待中的进程/线程，表明 V 操作不会阻塞；

P 操作是⽤在进⼊临界区之前，V 操作是⽤在离开临界区之后，这两个操作是必须成对出现的。

**锁：**

* 互斥锁（mutex）：加锁失败后，线程会**释放** **CPU** ，给其他线程；**对于互斥锁加锁失败⽽阻塞的现象，是由操作系统内核实现的**，加锁失败，内核将线程置为睡眠，直到资源释放再在合适的实际进行唤醒。互斥锁将唤醒交给内核，但是增加了上下文切换的开销。运行--睡眠--就绪
  * Mutex变量的值为1表示互斥锁空闲，这时某个进程调用lock可以获得锁。使用临界区，只能有一个线程对临界区数据进行操作
* 自旋锁：加锁失败后，线程会**忙等待**，直到它拿到锁；通过 CPU 提供的 CAS 函数（*Compare And Swap*），在「⽤户态」完成加锁和解锁操作，不会主动产   ⽣线程上下⽂切换。
* 读写锁：
  * 读优先锁：如果阻塞的线程有读操作的，就先执行，没有读再执行写
  * 写优先锁：如果阻塞的线程有写操作的，就先执行，没有写再执行读
  * 公平读写锁：将线程放入阻塞队列，先来先执行，可以避免某一类线程被饿死
* 乐观锁与悲观锁





# 2. 内存管理

## 1. 虚拟内存

我们程序所使⽤的内存地址叫做 **虚拟内存地址**（Virtual Memory Address）

实际存在硬件⾥⾯的空间地址叫 **物理内存地址**（Physical Memory Address）

使用虚拟内存可以将各个进程所使用的地址隔离，防止多个进程引用同一个地址造成的数据错误。

虚拟内存与物理内存的关系：分段、分页、段页式

## **2. 分段：段选择因子+段内偏移量**

​	分段的好处就是能产⽣连续的内存空间，但是会出现内存碎⽚和内存交换的空间太⼤的问题。

​	**段选择因⼦**就保存在段寄存器⾥⾯。段选择⼦⾥⾯最重要的是**段号**，⽤作段表的索引。**段表**⾥⾯保存的是这个**段的基地址、段的界限和特权等级**等。

虚拟地址中的**段内偏移量**应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。

![](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20210530105243380.png)

​		虚拟地址是通过**段表**与物理地址进⾏映射的，分段机制会把程序的虚拟地址分成 4 个段，每个段在段表中有⼀个项，在这⼀项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址。

​		**存在问题：**内存碎片（需要进行内存交换），内存交换效率低

## **3. 分页：页号+页内偏移**

​		**分⻚是把整个虚拟和物理内存空间切成⼀段段固定尺⼨的⼤⼩。**虚拟地址与物理地址之间通过**⻚表**来映射，⻚表是存储在内存⾥的，**内存管理单元** （*MMU*）就做将虚拟内存地址转换成物理地址的⼯作。⽽当进程访问的虚拟地址在⻚表中查不到时，系统会产⽣⼀个**缺⻚异常**，进⼊系统内核空间分配物理内存、更新进程⻚表，最后再返回⽤户空间，恢复进程的运⾏。

![image-20210530110035521](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20210530110035521.png)

![image-20210530110020386](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20210530110020386.png)

**如何解决内存碎片和交换效率低的问题：**

* **采用了分页，那么释放的内存都是以页为单位释放的，不会产生无法给进程使用的小内存**
* **如果内存空间不足，操作系统会将其他运行中的最近没有使用的内存页面释放掉，然后暂时写入硬盘（换出），等到需要的时候再加载（换入）。所以每次只需要写少数几页，效率较高。 在分页情况下，在加载页表之后，不需要将所有页加载。当程序运行时，需要加载虚拟内存里的指令和数据的时候，再加载对应的物理内存。**

**多级页表：**

​		如果进程特别多，那么因为分页的页比较小，那么页表就会非常多。此时，使用多级页表，配合局部性原理，可以解决页表太大的问题。

​		在原有的页表基础上，用页号对应页号的方式再增加一层。

​		**局部性原理**：一个程序运行时，在一小段时间内，只会用到程序和数据的很小一部分，仅把这部分程序和数据装入主存即可，更多的部分可以在需要用到时随时从辅存调入主存。在操作系统和相应硬件的支持下，数据在辅存和主存之间按程序运行的需要自动成批量地完成交换。

## 3. 段页式：分段+分页

​		先将程序划分为多个有逻辑意义的段，也就是前⾯提到的分段机制；接着再把每个段划分为多个⻚，也就是对分段划分出来的连续空间，再划分固定⼤⼩的⻚；

* 第⼀次访问段表，得到⻚表起始地址；
* 第⼆次访问⻚表，得到物理⻚号；
* 第三次将物理⻚号与⻚内位移组合，得到物理地址。

**💾分段式和分页式的区别：**

​		段式存储管理是一种符合用户视角的内存分配管理方案。在段式存储管理中，将程序的地址空间划分为若干段（segment），如代码段，数据段，堆栈段；这样每个进程有一个二维地址空间，相互独立，互不干扰。段式管理的优点是：没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片）

　　页式存储管理方案是一种用户视角内存与物理内存相分离的内存分配管理方案。在页式存储管理中，将程序的逻辑地址划分为固定大小的页（page），而物理内存划分为同样大小的帧，程序加载时，可以将任意一页放入内存中任意一个帧，这些帧不必连续，从而实现了离散分离。页式存储管理的优点是：没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）。

两者的不同点：

* 目的不同：分页是由于系统管理的需要而不是用户的需要，它是信息的物理单位；分段的目的是为了能更好地满足用户的需要，它是信息的逻辑单位，它含有一组其意义相对完整的信息；

* 大小不同：页的大小固定且由系统决定，而段的长度却不固定，由其所完成的功能决定；

* 地址空间不同： 段向用户提供二维地址空间；页向用户提供的是一维地址空间；

* 信息共享：段是信息的逻辑单位，便于存储保护和信息的共享，页的保护和共享受到限制；

* 内存碎片：页式存储管理的优点是没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）；而段式管理的优点是没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片）。



## 4. Linux内存管理

采用页式内存管理，但不可避免使用了段机制。

​		Linux 系统中的每个段都是从 0 地址开始的整个 4GB 虚拟空间（**32** 位环境下），也就是所有的段的起始地址都是⼀样的。这意味着，**Linux** 系统中的代码，包括操作系统本身的代码和应⽤程序代码，所⾯对的地址空间都是线性地址空间（虚拟地址），这种做法相当于屏蔽了处理器中的逻辑地址概念，段只被⽤于访问控制和内存保护。

​	在 Linux 操作系统中，虚拟地址空间的内部⼜被分为**内核空间和⽤户空间**两部分。

* 进程在⽤户态时，只能访问⽤户空间内存；

* 只有进⼊内核态后，才可以访问内核空间的内存

​    虽然每个进程都各⾃有独⽴的虚拟内存，但是**每个虚拟内存中的内核地址，其实关联的都是相同的物理内存**。这样，进程切换到内核态后，就可以很⽅便地访问内核空间内存。

![image-20210530113154081](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20210530113154081.png)

## 5. 页面置换算法

### 页面置换

当 CPU 访问的⻚⾯不在物理内存时，便会产⽣⼀个缺⻚中断，请求操作系统将所缺⻚调⼊到物理内存。

![image-20210530210626704](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20210530210626704.png)

​		找不到空闲⻚的话，就说明此时内存已满了，这时候，就需要「⻚⾯置换算法」选择⼀个物理⻚，如果该物理⻚有被修改过（脏⻚），则把它换出到磁盘，然后把该被置换出去的⻚表项的状态改成「⽆效的」，最后把正在访问的⻚⾯装⼊到这个物理⻚中。

​		页面置换：**当出现缺⻚异常，需调⼊新⻚⾯⽽内存已满时，选择被置换的物理⻚⾯**，也就是说选择⼀个物理⻚⾯换出到磁盘，然后把需要访问的⻚⾯换⼊到物理⻚。

### 💾页面置换算法

* 最佳页面置换算法（OPT）：置换在「未来」最⻓时间不访问的⻚⾯。只是理想状态，一般用作衡量标准。

* 先进先出置换算法（FIFO）：选择在内存驻留时间很⻓的⻚⾯进⾏中置换。

* 最近最久未使用的置换算法（LRU）：选择最⻓时间没有被访问的⻚⾯进⾏置换

* 时钟页面置换算法（LOCK）：把所有的⻚⾯都保存在⼀个类似钟⾯的「环形链表」中，⼀个表针指向最⽼的⻚⾯。当发⽣缺⻚中断时，算法⾸先检查表针指向的⻚⾯：

  * 如果它的访问位位是 0 就淘汰该⻚⾯，并把新的⻚⾯插⼊这个位置，然后把表针前移⼀个位置；

  * 如果访问位是 1 就清除访问位，并把表针前移⼀个位置，重复这个过程直到找到了⼀个访问位为 0 的⻚⾯为⽌；

* 最不常用算法（LFU）：当发⽣缺⻚中断时，选择「访问次数」最少的那个⻚⾯，并将其淘汰。

## 💾6. 磁盘调度算法

磁盘调度算法的⽬的很简单，就是为了提⾼磁盘的访问性能，⼀般是通过优化磁盘的访问请求顺序来做到的。

* 先来先服务算法：先到来的请求，先被服务：**效率低**

![image-20210530211619488](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20210530211619488.png)

* 最短寻道时间优先算法：优先选择从当前磁头位置所需寻道时间最短的请求：**可能造成某一区域的请求饿死**

![image-20210530211638039](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20210530211638039.png)

* 扫描算法：磁头在⼀个⽅向上移动，访问所有未完成的请求，直到磁头到达该⽅向上的最后的磁道，才调换方向：**每个磁道的响应频率存在差异（靠中间的容易请求更容易被处理）**

![image-20210530211756112](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20210530211756112.png)

* 循环扫描算法：只有磁头朝某个特定⽅向移动时，才处理磁道访问请求，⽽返返回中途不处理任何请求回时直接快速移动⾄最靠边缘的磁道，**磁道只响应⼀个⽅向上的请求**。

  ![image-20210530211947368](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20210530211947368.png)



* LOOK 与 C-LOOK 算法：分别对扫描算法和循环扫描算法进行优化。
  * **磁头在移动到「最远的请求」位置，然后⽴即反向移动。**
  * 磁头在每个⽅向上仅仅移动到最远的请求位置，然后⽴即反向移动，⽽不需要移动到磁盘的最始端或最末端

## 💾7. 内存结构（金字塔型）

![img](http://images.cnitblog.com/blog/558323/201309/20193847-5ab92cc7103f4e7fbd61f5d15f833501.jpg)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210601225805369.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZseWVyc2JveQ==,size_16,color_FFFFFF,t_70#pic_center)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210601225826266.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZseWVyc2JveQ==,size_16,color_FFFFFF,t_70#pic_center)

从上到下，速度依次变慢，容量逐渐增大。L1,L2是单个CPU私有的，L3是所有CPU共享

因为CPU的频率太快了，快到主存跟不上，这样在处理器时钟周期内，CPU常常需要等待主存，浪费资源。所以cache的出现，是为了缓解CPU和内存之间速度的不匹配问题。原理就是局部性原则：

A. 时间局部性：如果某个数据被访问，那么在不久的将来它很可能被再次访问；
B.空间局部性：如果某个数据被访问，那么与它相邻的数据很快也可能被访问；

# 3. 文件管理

## 1. 基本概念

* 索引节点 inode：记录文件的元信息，⽐如 inode 编号、⽂件⼤⼩、访问权限、创建时间、修改时间、**数据在磁盘的位置**等等。文件与索引节点一一对应，索引节点也会存储在硬盘中，占用磁盘空间
* 目录项：⽤来记录⽂件的名字、**索引节点指针**以及与其他⽬录项的层级关联关系。多个⽬录项关联起来，就会形成⽬录结构，但它与索引节点不同的是，**⽬录项是由内核维护的⼀个数据结构，不存放于磁盘，⽽是缓存在内存**。
* 扇区：磁盘读写的最小单位，512B
* 逻辑块：多个扇区组成逻辑块，每次读写的最⼩单位就是逻辑块。
* 磁盘进⾏格式化的时候，会被分成三个存储区域，分别是超级块、索引节点区和数据块区。
  * 超级块，⽤来存储⽂件系统的详细信息，⽐如块个数、块⼤⼩、空闲块等等。当⽂件系统挂载时进⼊内存；
  * 索引节点区，⽤来存储索引节点；当⽂件被访问时进⼊内存；
  * 数据块区，⽤来存储⽂件或⽬录数据；
* 虚拟文件系统：在⽤户层与⽂件系统层引⼊了中间层，对用户提供统一接口 可以分为：磁盘的文件系统，内存的文件系统，网络的文件系统

## 💾2. 文件存储

* 连续空间存放：**⽂件存放在磁盘「连续的」物理空间中**。读写效率高，但是会产生磁盘碎片，不易扩展

* 非连续空间存放：

  * 链表
    * 隐式链表：**⽂件头要包含「第⼀块」和「最后⼀块」的位置，并且每个数据块⾥⾯留出⼀个指针空间，⽤来存放下⼀个数据块的位置**
      * 无法直接访问某一部分数据，需要从头开始遍历（只有上一个节点存储有下一个节点的位置）
      * 如果某一部分损坏，则文件就损坏了
    * 显示链表：**把⽤于链接⽂件各数据块的指针，显式地存放在内存的⼀张链接表中，该表在整个磁盘仅设置⼀张，每个表项中存放链接指针，指向下⼀个数据块号**
      * 提高了检索速度，大大减少了磁盘访问量
      * 不适用于大磁盘：因为链接指针会很多，占用空间
  * 索引：为每个⽂件创建⼀个「**索引数据块**」，⾥⾯存放的是**指向⽂件数据块的指针列表**，**⽂件头需要包含指向「索引数据块」的指针**，这样就可以通过⽂件头知道索引数据块的位置，再通过索引数据块⾥的索引信息找到对应的数据块。

  ![image-20210530213824527](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20210530213824527.png)

  优点：文件的创建、增大、缩小都很方便、没有碎片产生、支持顺序读写和随机读写

  * 大文件的存放：
    * 链表加索引：文件头使用链表，有多个索引数据块指针，一段使用完了就指向下一段：**在索引数据块留出⼀个存放下⼀个索引数据块的指针**
    * 多级索引块：**通过⼀个索引块来存放多个索引数据块**

![image-20210530214332902](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20210530214332902.png)

## 💾3. Unix文件存储

根据⽂件的⼤⼩，存放的⽅式会有所变化：

* 如果存放⽂件所需的数据块⼩于 10 块，则采⽤直接查找的⽅式；

* 如果存放⽂件所需的数据块超过 10 块，则采⽤⼀级间接索引⽅式；如果前⾯两种⽅式都不够存放⼤⽂件，则采⽤⼆级间接索引⽅式；

* 如果⼆级间接索引也不够存放⼤⽂件，这采⽤三级间接索引⽅式；

那么，⽂件头（*Inode*）就需要包含 13 个指针：

* 10 个指向数据块的指针；

* 第 11 个指向索引块的指针；

* 第 12 个指向⼆级索引块的指针；
* 第 13 个指向三级索引块的指针；

灵活的支持了小文件和大文件的存储

## 4. 空闲空间管理

* 空闲表法：为所有空闲空间建⽴⼀张表，表内容包括空闲区的第⼀个块号和该空闲区的块个数：**连续的**
* 空闲链表法：使⽤「链表」的⽅式来管理空闲空间，每⼀个空闲块⾥有⼀个指针指向下⼀个空闲块：**分散的**
* 位图法：是利⽤⼆进制的⼀位来表示磁盘中⼀个盘块的使⽤情况，磁盘上所有的盘块都有⼀个⼆进制位与之对应。但是一个位图块能表示的太小，一般是多个组合

## 5. 软连接和硬链接

* 硬连接：**多个⽬录项中的「索引节点」指向⼀个⽂件**。**硬链接是不可⽤于跨⽂件系统的**。**只有删除⽂件的所有硬链接以及源⽂件时，系统才会彻底删除**

**该⽂件。**

* 软连接：相当于重新创建⼀个⽂件，这个⽂件有**独⽴的** **inode**，但是这个**⽂件的内容是另外⼀个⽂件的路径**，所以访问软链接的时候，实际上相当于访问到了另外⼀个⽂件，所以**软链接是可以跨⽂件系统的**，甚⾄**⽬标⽂件被删除了，链接⽂件还是在的，只不过指向的⽂件找不到了⽽已。**



# 4. 设备管理

## 1. 基本概念

* 根据 **是否利⽤标准库缓冲**，可以把⽂件 I/O 分为缓冲I/O 和⾮缓冲I/O：
  * 缓冲 I/O，利⽤的是标准库的缓存实现⽂件的加速访问，⽽标准库再通过系统调⽤访问⽂件。
  * ⾮缓冲 I/O，直接通过系统调⽤访问⽂件，不经过标准库缓存。
* 根据 **是否利⽤操作系统的缓存**，可以把⽂件 I/O 分为直接 I/O 与⾮直接 I/O：
  * 直接 I/O，不会发⽣内核缓存和⽤户程序之间数据复制，⽽是直接经过⽂件系统访问磁盘
  * ⾮直接 I/O，读操作时，数据从内核缓存中拷⻉给⽤户程序，写操作时，数据从⽤户程序拷⻉给内核缓存，再由内核决定什么时候写⼊数据到磁盘。
* 阻塞I/O与非阻塞I/O：阻塞等待的是「**内核数据准备好**」和「**数据从内核态拷⻉到⽤户态**」这两个过程
* 同步与异步

![image-20210530223211310](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20210530223211310.png)

* 设备控制器：屏蔽设备之间的差异，交由操作系统统一管理。设备控制器具有芯片，可以执行逻辑，拥有自己的寄存器：
  * 数据寄存器，CPU 向 I/O 设备写⼊需要传输的数据
  * 命令寄存器，CPU 发送⼀个命令，告诉 I/O 设备，要进⾏输⼊/输出操作，于是就会交给 I/O 设备去⼯作，任务完成后，会把状态寄存器⾥⾯的状态标记为完成
  * 状态寄存器，⽬的是告诉 CPU ，现在已经在⼯作或⼯作已经完成。状态寄存标记成已完成，CPU 才能发送下⼀个字符和命令。
* **💾DMA（**Direct Memory Access）：它可以使得设备在CPU 不参与的情况下，能够⾃⾏完成把设备 I/O 数据放⼊到内存。
  * CPU 需对 DMA 控制器下发指令，告诉它想读取多少数据，读完的数据放在内存的某个地⽅就可以了；
  * 接下来，DMA 控制器会向磁盘控制器发出指令，通知它从磁盘读数据到其内部的缓冲区中，接着磁盘控制器将缓冲区的数据传输到内存；
  * 当磁盘控制器把数据传输到内存的操作完成后，磁盘控制器在总线上发出⼀个确认成功的信号到DMA 控制器；
  * DMA 控制器收到信号后，DMA 控制器发中断通知 CPU 指令完成，CPU 就可以直接⽤内存⾥⾯现成的数据了；

## 2. I/O控制方式

* 轮询等待
* 中断
  * 软中断：例如代码调⽤ INT 指令触发
  * 硬中断：硬件通过中断控制器触发的。

## 💾3. linux的5中I/O调度算法

* 没有调度算法：不对⽂件系统和应⽤程序的 I/O 做任何处理，这种算法常⽤在虚拟机 I/O 中，此时磁盘 I/O 调度算法交由物理机系统负责。
* 先⼊先出调度算法：
* 完全公平调度算法：为每个进程维护了⼀个I/O 调度队列，并按照时间⽚来均匀分布每个进程的 I/O 请求。
* 优先级调度：优先级⾼的 I/O 请求先发⽣， 它适⽤于运⾏⼤量进程的系统
* 最终期限调度算法：分别为读、写请求创建了不同的 I/O 队列，这样可以提⾼机械磁盘的吞吐量，并确保达到最终期限的请求被优先处理，适⽤于在 I/O 压⼒⽐较⼤的场景

## 💾4. 键入A之后的操作

* 那当⽤户输⼊了键盘字符，**键盘控制器**就会产⽣扫描码数据，并将其缓冲在键盘控制器的寄存器中，紧接着键盘控制器通过总线给 CPU 发送**中断请求**。
* CPU 收到中断请求后，操作系统会**保存被中断进程的** **CPU** **上下⽂**，然后调⽤键盘的**中断处理程序**。
* 键盘的中断处理程序是在**键盘驱动程序**初始化时注册的，那键盘**中断处理函数**的功能就是从键盘控制器的寄存器的缓冲区读取扫描码，再根据扫描码找到⽤户在键盘输⼊的字符，如果输⼊的字符是显示字符，那就会把扫描码翻译成对应显示字符的 ASCII 码，⽐如⽤户在键盘输⼊的是字⺟ A，是显示字符，于是就会把扫描码翻译成 A 字符的 ASCII 码。
* 得到了显示字符的 ASCII 码后，就会把 ASCII 码放到「读缓冲区队列」，接下来就是要把显示字符显示屏幕了，显示设备的驱动程序会定时从「读缓冲区队列」读取数据放到「写缓冲区队列」，最后把「写缓冲区队列」的数据⼀个⼀个写⼊到显示设备的控制器的寄存器中的数据缓冲区，最后将这些数据显示在屏幕⾥。
* 显示出结果后，**恢复被中断进程的上下⽂**

## 💾5. 零拷贝（类比网络编程）

传统拷贝过程发生了4次用户态和内核态的切换，以及4次拷贝过程

![image-20210530224705997](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20210530224705997.png)

**mmap + write**（使用的直接内存）

read() 系统调⽤的过程中会把内核缓冲区的数据拷⻉到⽤户的缓冲区⾥，于是为了减少这⼀步开销，我们可以⽤ mmap() 替换 read() 系统调⽤函数。

mmap() 系统调⽤函数会直接把内核缓冲区⾥的数据「**映射**」到⽤户空间，这样，操作系统内核与⽤户空间就不需要再进⾏任何的数据拷⻉操作。

![image-20210530224946505](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20210530224946505.png)

**sendfile**（使用指令直接再内核态进行拷贝）

sendfile可以替代前⾯的 read() 和 write() 这两个系统调⽤，这样就可以减少⼀次系统调⽤，也就减少了 2 次上下⽂切换的开销。

![image-20210530225039951](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20210530225039951.png)

**SG-DMA **

从 Linux 内核 2.4 版本开始起，对于⽀持⽹卡⽀持 SG-DMA 技术的情况下， sendfile() 系统调⽤的过程发⽣了点变化

* 第⼀步，通过 DMA 将磁盘上的数据拷⻉到内核缓冲区⾥；
* 第⼆步，缓冲区描述符和数据⻓度传到 socket 缓冲区，这样⽹卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷⻉到⽹卡的缓冲区⾥，此过程不需要将数据从操作系统内核缓冲区拷⻉到 socket缓冲区中，这样就减少了⼀次数据拷⻉；



## 💾6. I/O多路复用

### 1. socket模型（和网络编程一样）

![image-20210530225412588](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20210530225412588.png)

* **最⼤ TCP 连接数 = 客户端 IP 数×客户端端⼝数。**

* C10K： C 是 Client 单词⾸字⺟缩写，C10K 就是单机同时处理 1 万个请求的问题

* **⽂件描述符**，Socket 实际上是⼀个⽂件，也就会对应⼀个⽂件描述符。在 Linux 下，单个进程打开的⽂件描述符数是有限制的，没有经过修改的值⼀般都是 1024，不过我们可以通过 ulimit 增⼤⽂件描述符的数⽬；

* **系统内存**，每个 TCP 连接在内核中都有对应的数据结构，意味着每个连接都是会占⽤⼀定内存的；

### 2. select/poll

对于 select 这种⽅式，需要进⾏ **2** **次「遍历」⽂件描述符集合**，⼀次是在内核态⾥，⼀个次是在⽤户态⾥ ，⽽且还会发⽣ **2** **次「拷⻉」⽂件描述符集合**，先从⽤户空间传⼊内核空间，由内核修改后，再传出到⽤户空间中。

* select 使⽤固定⻓度的 BitsMap，表示⽂件描述符集合，⽽且所⽀持的⽂件描述符的个数是有限制的。

* poll 不再⽤ BitsMap 来存储所关注的⽂件描述符，取⽽代之⽤动态数组，以链表形式来组织，突破了select 的⽂件描述符个数限制，当然还会受到系统⽂件描述符限制。

但是 poll 和 select 并没有太⼤的本质区别，**都是使⽤「线性结构」存储进程关注的** **Socket** **集合，因此都需要遍历⽂件描述符集合来找到可读或可写的** Socket**，时间复杂度为***O(n)，⽽且也需要在⽤户态与内核态之间拷⻉⽂件描述符集合，这种⽅式随着并发数上来，性能的损耗会呈指数级增⻓。

### 3. epoll

epoll 通过两个⽅⾯，很好解决了 select/poll 的问题。

第⼀点，epoll 在内核⾥使⽤**红⿊树来跟踪进程所有待检测的⽂件描述字**，把需要监控的 socket 通过epoll_ctl() 函数加⼊内核中的红⿊树⾥，红⿊树是个⾼效的数据结构，增删查⼀般时间复杂度是O(logn) ，通过对这棵⿊红树进⾏操作，这样就不需要像 select/poll 每次操作时都传⼊整个 socket 集合，只需要传⼊⼀个待检测的 socket，减少了内核和⽤户空间⼤量的数据拷⻉和内存分配。

第⼆点， epoll 使⽤事件驱动的机制，内核⾥**维护了⼀个链表来记录就绪事件**，当某个 socket 有事件发⽣时，通过回调函数内核会将其加⼊到这个就绪事件列表中，当⽤户调⽤ epoll_wait() 函数时，只会返回有事件发⽣的⽂件描述符的个数，不需要像 select/poll 那样轮询扫描整个 socket 集合，⼤⼤提⾼了检测的效率。

![image-20210530230243995](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20210530230243995.png)

epoll ⽀持两种事件触发模式，分别是**边缘触发（edge-triggered**，ET）和**⽔平触发（level-triggered，**LT）。

* 使⽤边缘触发模式时，当被监控的 Socket 描述符上有可读事件发⽣时，**服务器端只会从** **epoll_wait中苏醒⼀次**，即使进程没有调⽤ read 函数从内核读取数据，也依然只苏醒⼀次，因此我们程序要保证⼀次性将内核缓冲区的数据读取完；
* 使⽤⽔平触发模式时，当被监控的 Socket 上有可读事件发⽣时，**服务器端不断地从** **epoll_wait** **中苏醒，直到内核缓冲区数据被** **read** **函数读完才结束**，⽬的是告诉我们有数据需要读取；

**select/poll 只有⽔平触发模式，epoll 默认的触发模式是⽔平触发，也可以根据应用场景设置为边缘触发（边缘触发一般与非阻塞I/O使用）**



## 7 .Reactor和 Proactor

* Reactor：基于同步I/O 三个对象

  * Reactor 对象的作⽤是监听和分发事件；
  * Acceptor 对象的作⽤是获取连接；
  * Handler 对象的作⽤是处理业务；

  三种模式：

  *  Reactor 单进程 / 线程：⽆法充分利⽤多核 CPU，⽽且处理业务逻辑的时间不能太⻓，否则会延迟响应
  * 单 Reactor 多线程：在只有⼀个 Reactor 对象来承担所有事件的监听和响应，⽽且只在主线程中运⾏，在⾯对瞬间⾼并发的场景时，容易成为性能的瓶颈的地⽅。
  * 多 Reactor 多进程 / 线程：主 Reactor 只负责监听事件，响应事件的⼯作交给了从 Reactor，Netty 和 Memcache 都采⽤了「多 Reactor 多线程」的⽅案

  ![image-20210531094608542](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20210531094608542.png)

* Proactor：基于异步I/O（类比一些AIO）

  先由操作系统将读写操作完成之后，再通知线程/进程进行处理

**对比：**

* **Reactor** **是⾮阻塞同步⽹络模式，感知的是就绪可读写事件**，**Proactor** **是异步⽹络模式， 感知的是已完成的读写事件**。
* **Reactor** **可以理解为「来了事件操作系统通知应⽤进程，让应⽤进程来处理」**，⽽ **Proactor** **可以理解为「来了事件操作系统来处理，处理完再通知应⽤进程**
* ⽆论是 Reactor，还是 Proactor，都是⼀种基于「事件分发」的⽹络编程模式

## 8. LINUX常用命令

* 查看网络配置  ipconfig 网口   或者 ip -s addr show dev 网口
* 查看socket信息： netstat -nlp  （不推荐，性能不好）   或者  ss -ltnp 
  * n 以数字形式显示
  * l 只显示listen状态socket
  * p 显示进程信息
  * t  只显示tcp连接
* 连通性和延时性：ping 地址 -c 5   （-c 5 发送5次ICMP包）
* 网络吞吐量： sar
  * sar -n DEV，显示⽹⼝的统计数据；
  * sar -n EDEV，显示关于⽹络错误的统计数据；
  * sar -n TCP，显示 TCP 的统计数据

